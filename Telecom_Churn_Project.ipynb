{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Churn Rate in Telecom Industry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# BaggingClassifier, AdaBoostClassifier, \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc=pd.read_csv('Telco-Customer-Churn.csv',na_values=[' ','/','?','$'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d3c81790a836>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_columns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#  option to view all the columns without missing any, in the outputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "pd.options.display.max_columns=None\n",
    "#  option to view all the columns without missing any, in the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-c3aa8dd07f84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'InternetService'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'No'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tc' is not defined"
     ]
    }
   ],
   "source": [
    "tc[tc['InternetService']=='No']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace 'No internet service' to No for the following columns\n",
    "replace_cols = [ 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "                'TechSupport','StreamingTV', 'StreamingMovies']\n",
    "for i in replace_cols : \n",
    "    tc[i]  = tc[i].replace({'No internet service' : 'No'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc['SeniorCitizen']=tc['SeniorCitizen'].replace([0,1],['No','Yes'])\n",
    "# 'SeniorCitizen' has only 1's and 0's and it is a categorical column so converting it into object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tc['customerID']\n",
    "#  customerID is the unqiue column and we cant get any insights from this, and hence it's removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tc.columns:\n",
    "    print(i,':',tc[i].nunique())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Except 'tenure','MonthlyCharges' and 'TotalCharges' all the other columns are categorical"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in tc.columns:\n",
    "    print(i,':',tc[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-e6cf537b75e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tc' is not defined"
     ]
    }
   ],
   "source": [
    "tc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=tc[tc['TotalCharges'].isnull()]\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "we have null values only in 'TotalCharges' and we could see nulls when Dependents ='Yes', SeniorCitizen='0' and tenure=0\n",
    "and hence we impute null values with the means accordingly for males and females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con=(tc['Dependents']=='Yes') \n",
    "imp_mean=tc[con]\n",
    "imp_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male,female=imp_mean['TotalCharges'].groupby(tc['gender']).mean()\n",
    "(male,female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con1=(tc['gender']=='Male')& (tc['tenure']==0)\n",
    "con2=(tc['TotalCharges'].isnull())\n",
    "con3=con1&con2\n",
    "tc[con3]=tc[con3].fillna(male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con1=(tc['gender']=='Female')& (tc['tenure']==0)\n",
    "con2=(tc['TotalCharges'].isnull())\n",
    "con3=con1&con2\n",
    "tc[con3]=tc[con3].fillna(female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catcols=tc.select_dtypes('object')\n",
    "catcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'catcols' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-90066bcb5056>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Taking all columns whose categories are more than 2 and check if they are significantly different\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcatcols\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcatcols\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'catcols' is not defined"
     ]
    }
   ],
   "source": [
    "# Taking all columns whose categories are more than 2 and check if they are significantly different\n",
    "l=[]\n",
    "for i in catcols.columns:\n",
    "    if catcols[i].nunique()>2:\n",
    "        l.append(i)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since there are more two categories we perform chi2_contingency\n",
    "# we consider those columns whose p_val is <0.05\n",
    "from scipy.stats import chi2_contingency\n",
    "f=[]\n",
    "for i in l:\n",
    "    cc=chi2_contingency(pd.crosstab(catcols['Churn'],catcols[i]))\n",
    "    if(cc[1]<=0.05):\n",
    "        f.append(i)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "From the above fun we decide to keep the values whose p value is <0.05 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking all columns whose categories are less than 2 and check if they are significantly different\n",
    "k=[]\n",
    "for i in catcols.columns:\n",
    "    if catcols[i].nunique()==2:\n",
    "        k.append(i)\n",
    "k.pop(-1) # since 'Churn' is our predictive varibale we remove it from here, to compare every categorical value with 'Churn'\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since there are two categories we perform proportions_ztest\n",
    "# we consider those columns whose p_val is <0.05\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "g=[]\n",
    "for i in k:\n",
    "    c=pd.crosstab(tc['Churn'],tc[i])\n",
    "    x1=c.iloc[1,1]\n",
    "    x2=c.iloc[1,0]\n",
    "    n1=c.iloc[:,1].sum()\n",
    "    n2=c.iloc[:,0].sum()\n",
    "    cc=proportions_ztest([x1,x2],[n1,n2])\n",
    "    if(cc[1]<=0.05):\n",
    "        g.append(i)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Gender and PhoneService are not statistically significant so we remove them for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-e3d547cdee33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# List of categorical whose p<0.05 after proportion_ztest and chi2_contingency test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mf_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Total number of required columns:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'f' is not defined"
     ]
    }
   ],
   "source": [
    "# List of categorical whose p<0.05 after proportion_ztest and chi2_contingency test\n",
    "f_list=f+g\n",
    "print(f_list,'\\n')\n",
    "print('Total number of required columns:',len(f_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc['Churn'].value_counts(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie(tc['Churn'].value_counts(),explode=(0,0.09),autopct='%1.1f%%',labels=('No','Yes'),shadow=True)\n",
    "plt.savefig('Churn pct')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes=plt.subplots(4,4,figsize=(20,20))\n",
    "axes=axes.flatten()\n",
    "for i in range(0,len(f_list)):\n",
    "    sns.countplot(tc[f_list[i]],hue=tc['Churn'],ax=axes[i])\n",
    "plt.tight_layout()\n",
    "plt.savefig('Attribute wise comparison with Churn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating one hot encoding for the selected columns\n",
    "tc_dum=pd.get_dummies(tc[f_list])\n",
    "tc_dum.head()\n",
    "print(tc_dum.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num=tc.select_dtypes(['int64','float'])\n",
    "num\n",
    "X=pd.concat([tc_dum,num],axis=1)\n",
    "y=tc['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,random_state = 7,test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg=LogisticRegression()\n",
    "logreg_result=logreg.fit(X_train,y_train)\n",
    "print(logreg_result.score(X_train,y_train))\n",
    "print(\"Training set score: {:.3f}\".format(logreg_result.score(X_train,y_train)))\n",
    "print(\"Test score: {:.3f}\".format(logreg_result.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred  = logreg.predict(X_test)\n",
    "y_proba = logreg.predict_proba(X_test)\n",
    "y_proba\n",
    "# y_proba consists of p and (1-p) values, but we use (1-p) values for roc curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.scatterplot(X_test,logreg.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import auc\n",
    "y_test1=y_test.replace(['Yes','No'],[True,False])\n",
    "y_train1=y_train.replace(['Yes','No'],[True,False])\n",
    "fpr, tpr, thresholds = roc_curve(y_test1, y_proba[:,1])\n",
    "areauc=auc(fpr,tpr)\n",
    "areauc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr,tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.title('ROC curve for Logistic Regression')\n",
    "plt.xlabel('False positive rate (1-Specificity)')\n",
    "plt.ylabel('True positive rate (Sensitivity)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tools import add_constant as add_constant\n",
    "import statsmodels.api as sm\n",
    "X_train1=sm.add_constant(X_train)\n",
    "logit_model=sm.Logit(y_train1,X_train1)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive Feature Elimination\n",
    "#  To find the best columns suitable for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "logit = LogisticRegression()\n",
    "\n",
    "rfe = RFE(logit,10)\n",
    "rfe = rfe.fit(X_train,y_train)\n",
    "\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)\n",
    "#identified columns Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idc_rfe = pd.DataFrame({\"rfe_support\" :rfe.support_,\n",
    "                       \"columns\" :X_train.columns ,\n",
    "                       \"ranking\" : rfe.ranking_,\n",
    "                      })\n",
    "cols = idc_rfe[idc_rfe[\"rfe_support\"] == True][\"columns\"].tolist()\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the RFE we filter the best columns where support is True\n",
    "X_train_rfe=X_train[cols]\n",
    "X_test_rfe=X_test[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF_model=RandomForestClassifier(random_state=10)\n",
    "RF_results=RF_model.fit(X_train_rfe,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = RF_model.predict(X_test_rfe)\n",
    "y_pred_train = RF_model.predict(X_train_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train,y_pred_train))\n",
    "print('Train Accuracy Score for Random Forest 1st attempt',accuracy_score(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred_test))\n",
    "print('Test Accuracy Score for Random Forest 1st attempt',accuracy_score(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "RF_model=RandomForestClassifier(n_estimators=10,random_state=10)\n",
    "param_grid_rf={'n_estimators':[11,12,13,9],'max_features':['auto','sqrt'],}\n",
    "clf=GridSearchCV(RF_model,param_grid_rf,cv=2)\n",
    "clf.fit(X_train_rfe,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_best_model=RandomForestClassifier(n_estimators=9,random_state=10)\n",
    "RF_best_model.fit(X_train_rfe,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred=clf.predict(X_train_rfe)\n",
    "y_test_pred=clf.predict(X_test_rfe)\n",
    "(y_train_pred,y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print(classification_report(y_train,y_train_pred))\n",
    "print('Train Accuracy Random Forest after Grid Search CV :',accuracy_score(y_train,y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_test_pred))\n",
    "print('Test Accuracy Random Forest after Grid Search CV :',accuracy_score(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred=pd.DataFrame(RF_best_model.predict(X_test_rfe))\n",
    "y_proba_rf = RF_best_model.predict_proba(X_test_rfe)\n",
    "# y_proba_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test1=y_test.replace(['Yes','No'],[True,False])\n",
    "y_train1=y_train.replace(['Yes','No'],[True,False])\n",
    "fpr1, tpr1, thresholds = roc_curve(y_test1, y_proba_rf[:,1])\n",
    "(fpr1, tpr1)\n",
    "# print(len(y_proba_rf[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr1,tpr1)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.title('ROC curve for Logistic Regression')\n",
    "plt.xlabel('False positive rate (1-Specificity)')\n",
    "plt.ylabel('True positive rate (Sensitivity)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_model = BaggingClassifier(DecisionTreeClassifier(random_state=1))\n",
    "bag_model.fit(X_train_rfe,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_pred = bag_model.predict(X_test_rfe)\n",
    "accuracy_score(y_test, bag_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_cm = confusion_matrix(y_test, bag_pred)\n",
    "sns.heatmap(bag_cm,annot=True,fmt='d',cmap='Blues_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,bag_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bag=bag_model.predict(X_test_rfe)\n",
    "y_pred_proba_bag=bag_model.predict_proba(X_test_rfe)\n",
    "fpr3, tpr3, thresholds = roc_curve(y_test1, y_pred_proba_bag[:,1])\n",
    "(fpr3, tpr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr3,tpr3)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.title('ROC curve for Logistic Regression')\n",
    "plt.xlabel('False positive rate (1-Specificity)')\n",
    "plt.ylabel('True positive rate (Sensitivity)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=KNeighborsClassifier()\n",
    "knn.fit(X_train_rfe,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_pred_knn,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_knn=knn.predict(X_test_rfe)\n",
    "y_pred_proba_knn=knn.predict_proba(X_test_rfe)\n",
    "fpr2, tpr2, thresholds = roc_curve(y_test1, y_pred_proba_knn[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr2,tpr2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.title('ROC curve for Logistic Regression')\n",
    "plt.xlabel('False positive rate (1-Specificity)')\n",
    "plt.ylabel('True positive rate (Sensitivity)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradiant Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb_model = GradientBoostingClassifier(learning_rate=0.01,random_state=1)\n",
    "gb_model.fit(X_train_rfe,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_pred = gb_model.predict(X_test_rfe)\n",
    "accuracy_score(y_test, gb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gb=gb_model.predict(X_test_rfe)\n",
    "y_pred_proba_gb=gb_model.predict_proba(X_test_rfe)\n",
    "fpr4, tpr4, thresholds = roc_curve(y_test1, y_pred_proba_gb[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curves for Logistic Regression and Random Forest\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr,tpr)# log reg\n",
    "plt.plot(fpr1,tpr1)# rand for\n",
    "plt.plot(fpr2,tpr2)# KNN\n",
    "plt.plot(fpr3,tpr3)# Bagging\n",
    "plt.plot(fpr4,tpr4)# Gradiant Boosting\n",
    "plt.grid()\n",
    "plt.title('Algorithm Wise ROC Comparison')\n",
    "plt.legend(['Logistic Regression','Random Forest','KNN','Bagging','Gradiant Boosting'])\n",
    "plt.savefig('ROC Curves')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [('Logistic Regression', LogisticRegression()),  \n",
    "          ('Random Forest', RandomForestClassifier()), \n",
    "          ('KNN', KNeighborsClassifier()), \n",
    "          ('Bagging',BaggingClassifier()),\n",
    "          ('Gradient Boosting', GradientBoostingClassifier())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "results = []\n",
    "names = []\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X_test_rfe, y_test, cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "plt.boxplot(results)\n",
    "plt.title('Algorithm Wise Test Accuracy Comparison')\n",
    "ax.set_xticklabels(names,rotation=45)\n",
    "plt.ylabel('')\n",
    "plt.savefig('Algorithm Wise Test Accuracy Comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_train = 7\n",
    "results_train = []\n",
    "names_train = []\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=seed_train)\n",
    "    cv_results = cross_val_score(model, X_train_rfe, y_train, cv=kfold, scoring='accuracy')\n",
    "    results_train.append(cv_results)\n",
    "    names_train.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "plt.boxplot(results_train)\n",
    "plt.title('Algorithm Wise Train Accuracy Comparison')\n",
    "ax.set_xticklabels(names_train,rotation=45)\n",
    "plt.ylabel('')\n",
    "plt.savefig('Algorithm Wise Train Accuracy Comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-e9d6a67583f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvif\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mvif\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"VIF Factor\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvariance_inflation_factor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
